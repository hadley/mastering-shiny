# Performance {#performance}

```{r, include = FALSE}
source("common.R")
options(tibble.print_min = 6, tibble.print_max = 6)
```

Shiny can support thousands or tens of thousands of users, if developed correctly.
But most Shiny apps were quickly thrown together to solve a pressing analytic need, and often start with pretty terrible performance.
In some ways, this is a feature of Shiny --- it allows you to quickly prototype a proof of concept that works for you, before figuring out how to make it fast so that it can be used by a bunch of people simultaneously.
But if you don't realise that app is likely because you've optimised for human iteration speed), making a Shiny app available to many people will be frustrating.

Fortunately, however, Shiny comes with a bunch of tools to help improve performance.
In this chapter you'll learn:

-   How to use shinyloadtest to simulate the use of your app by many people.
    This allows you to figure out if you have a problem, and to measure the impact of your performance improvement.

-   To use profvis to identify performance bottlenecks.
    It is extremely difficult to develop a good intuition for what parts of your app are likely to be slow.
    Fortunately there's no need because we can measure and visualise.

-   A grab bag of useful techniques to improve performance, particularly focussing on techniques that allow you to take advantage of multiple users.

-   We'll finish up with a little applied psychology to give a few techniques that can help your app *feel* as fast as possible.

But to get started, lets build up your mental model of Shiny performance with a restaurant analogy.

```{r setup}
library(shiny)
```

Particularly thanks go to my RStudio colleagues Joe Cheng, Sean Lopp, and Alan Dipert, whose RStudio::conf() talks were particularly helpful when writing this chapter.

## Dining at restaurant Shiny

(Thanks to Sean Lopp for this analogy from his rstudio::conf(2018) talk [Scaling Shiny to 10,000 users](https://rstudio.com/resources/rstudioconf-2018/scaling-shiny/){.uri}.
I highly recommend watching it if you have any doubt that Shiny apps can handle thousands of users.)

To help improve your mental model of app serving, it's useful to think of a Shiny app like a restaurant.
Each customer (user) comes in and makes an order which is prepared and served by a chef (the R process).
One chef can make a sandwich for customer A, then a soup for customer B, ... Unlike chefs, however, R is single-process, which means that it can only do one thing at a time --- if Shiny is making an omelette, it can't start some pancakes cooking.
This is fine if all the recipe are quick to cook, but if you asked a R-Chef to make a two hour stew, they couldn't do anything else in the meantime.
(Unless you learn about async programming, which basically lets R work on multiple things at the same time <https://rstudio.github.io/promises/>).

One chef can serve multiple customers, but as you get more customers, you're likely to want to hire more chefs.
But at some point there's so many that they get in each others' way --- there's still only one oven, one grill, one refrigerator, etc.
So at some point, you're going to need to add a new restaurant (server).

(R is single threaded which means the chef is very focussed --- they can only cook one thing at a time. This is fine if they're doing something quick, but if you ask them to make a stew, all the other customers have to wait for a couple of hours until they're done. While you can work around this problem by adding more single track chefs, a better way is to )

Just like you can serve a customer meal made in multiple restaurants with a new restaurant, there's no way to serve one user from multiple servers, so this also needs to be coupled with a load balancer which automatically sends customers to the emptiest restaurant.
We won't talk more about scaling out in this chapter (because while the details are straightforward, they depend entirely on your deployment infrastructure), but it's good to know this option exists, and allows you app to scale to any number of users.

There are three main ways to make your app faster:

-   Make it faster for a single user.
    Not necessarily easy, but also not directly related to shiny.
    If you're concerned about single user performance (i.e.Â it's just you using the app), it's very unlikely that Shiny is the bottleneck.
    Instead, improving the performance of your app is really about improving the performance of your R code.
    Many of the same techniques apply; in particular you'll still need to profile the performance of your app.
    Some advice in <https://adv-r.hadley.nz/perf-measure.html> and <https://adv-r.hadley.nz/perf-improve.html>.

-   Make it faster for multiple users on the same server.

-   Make it faster by running more servers.
    Shiny is horizontally scalable, which means that you can always make it faster by providing more servers.
    Shiny and R scale linearly per processor --- if you need to support more users you can just use more processors.

-   Hire a prep cook

Question becomes whether it's cheaper to pay for more computing, or to pay for your time to fit more users on one computer.
Typically it's going to be combination, because there are often many big easy wins because you've worked on the app on your own computer as a solo user.

## Benchmark

The first step is always to identify if you have a problem.
How can you tell if your app is going to be slow for multiple users without deploying it and have a bunch of your friends try it out at the same time?

The is the problem that the [shinyloadtest](https://rstudio.github.io/shinyloadtest/) package is designed to solve.
It has four basic steps:

1.  Run your app locally and use `shinyloadtest::record_session()` to record an prototypical user session.
2.  Replay the script with multiple users using shinycannon (a command line tool included with shinyload test)
3.  Analyse the results using `shinyloadtest::load_runs()` and `shinyloadtest::report()`.

For a demo of the whole process from benchmarking to profiling to improvement and back, I recommend Joe Cheng's rstudio::conf(2019) keynote [Shiny in production: principles, best practices, and tools](https://rstudio.com/resources/rstudioconf-2019/shiny-in-production-principles-practices-and-tools/){.uri} where he works through the whole process with a realistic app.
This is also written in the [scaling an app case study](https://rstudio.github.io/shinyloadtest/articles/case-study-scaling.html) on the shinyloadtest website.

### Recording

Start your app then run `shinyloadtest::record_session`.
If you're doing this all locally you'll need to use two different R session --- one for Shiny, and one for shinyloadtest.
You'll need to copy and paste the url that `runApp()` gives you:

```{r, eval = FALSE}
runApp("myapp.R")
#> Listening on http://127.0.0.1:7716
```

Then in another R session, run `shinyloadtest::record_session(http://127.0.0.1:7716)`.

I recommend making a written script for yourself to guide your actions.
Your measurements will only be as good as your script.
Try to capture all of the most important actions in a realistic way, adding pauses to reflect the thinking time that a real user would take

Note that while you can do everything on your own laptop, you're best off simulating the actual deployment as closely as possible.
For example, if you're going to deploy the app publicly using Shiny Server pro, make sure to replay the user session against your live app.
And the server that you record on must match the server you replay on.

### Replay

To replay your script you need a separate command line tool called shinycannon.
Unfortunately this is a bit more work to install because it's written in Java rather than R.
Java is particularly well suited to this problem of running tens or hundreds of web requests in parallel, using as few computational resources as possible (so it's possible for your laptop to both run the app and simulate many users if needed).

So start by following the instructions at <https://rstudio.github.io/shinyloadtest/#shinycannon>

Then you'll run shinycannon from the terminal like:

    shinycannon recording.log {app_url} --workers 10 --loaded-duration-minutes 5 --output-dir run1

You'll need to choose how many workers to run (based on how many people you expect will use your app simultaneously) and how long to run for.
If the run time is longer than your script, shinycannon will just re-run it from the beginning.
If you're load testing for the first time, you should pick a small number of workers and short time, as it's likely the problems will be obvious.

### Analysis

```{r, eval = FALSE}
library(shinyloadtest)
df <- load_runs(demo = "~/Downloads/scaling_case_study_run5/")
slt_session_duration(df)
```

Full details in <https://rstudio.github.io/shinyloadtest/articles/analyzing-load-test-logs.html>

Red line shows the time that the original recording took.
If you are thinking about scaling horizontally, you will want to increase the number of workers until you see this be far away.
this process will also help you to understand how many how many customers each chef can serve (how many users per R process) and how many chefs can fit in a kitchen (how many processes per server), and hence how many kitchens you need to build.

## Profiling

If you want a chef to serve more customers, you need to do some time and motion studies to figure out what's slowing them down.
The equivalent in R is profiling, which basically regularly inspects the running code and records the call stack at each instant.

Note that it only records when the R is active; not when it's waiting (e.g. in `Sys.sleep()` or when downloading data over http), or when C code is being called.
This can be misleading, but does serve to concentrate your attention on what you can actually control within R.

What is call stack.
Section \@ref(reading-tracebacks).
Call stacks grow and shrink over time.

```{r, eval = FALSE}
library(profvis)
profvis(runApp())
# perform the operation that's slow
# close the app
# look at the visualisation
```

Call stack diagram --- show code, then draw tree, then collapse into rectangles, then make width proportional to time.

Goal is to find the one slowest thing, because that has the highest payoff.
Once you've found it, brainstormed possible improvements and then tried them out, you look for the next slower thing.

Once you've isolated a slow part, if it's not already in a function, I highly recommend pulling it out as in Chapter \@ref(scaling-functions).
That will make it much easier to optimise.
Also recommend testing it, because it at least in my experience the easiest way to make code faster is to make it incorrect ðŸ˜†.

## Do less work

Most techniques are general --- follow advice in Advanced R. But there's some particular techniques unique to Shiny because of the multiple users.
Often you can save time by sharing work across users.
Don't repeat yourself.

For more, I highly recommend watching Alan Dipert's rstudio::conf(2018) talk [Making Shiny fast by doing as little as possible](https://rstudio.com/resources/rstudioconf-2018/make-shiny-fast-by-doing-as-little-work-as-possible/){.uri}.

### Data import

First, make sure that any common data is loaded outside of the server function, in the body of the `app.R`.
That ensures that the data is once per process, rather than once per user, which saves both time and memory.

Next, check that you're using the most efficient way to load your data:

-   If you have a flat file, try `data.table::fread()` or `vroom::vroom()` instead of `read.csv()` or `read.table()`.

-   If you have a data frame, saving with `arrow::write_feather()` and reading, try `arrow::read_feather()`.
    (<https://ursalabs.org/blog/2020-feather-v2/>)

-   Complex non-data frame, try `qs::qread()`/`qs::qsave()` instead of `readRDS()`/`saveRDS()`.

If that's still too slow, and each user only tends to use a small part of the full dataset, consider loading the data in a database.
Then you can easily retrieve only the data that the user specifically asks for.

### Data processing

After loading data from disk, it's common to do some basic cleaning and aggregation.
If this is expensive, you should consider using cron job (or scheduled RMarkdown reports) or similar to save the precomputed results.
To continue the restaurant analogy --- this is like hiring a prep chef who comes in at 3am (when there are no customers) and does a bunch of work so that that chefs can be as efficient as possible.

### Share work across users

We discussed a specific type of caching for graphics in Section \@ref(cached-plots).
Shiny 1.6.0 introduces a general tool that works with any reactive: `withCache()`.
By default, reactives are already cached, but they only cache the previous value.
`withCache()` allows you to cache more values and to share those values across users.

To use the cache effectively, you'll need to have identified that a specific reactive is a bottleneck and done some thinking to make sure that the reactive is used multiple times or by multiple users.
(Also note that the impact of caching on your load tests is likely to be an over estimated because every simulated user does exactly the same thing, making it a perfect use case for caching).
Then:

`withCache()` is easy to use.
Just pipe the reactive into `withCache()`:

```{r, eval = FALSE}
r <- reactive(slow_function(input$x, input$y)) %>% 
  withCache(input$x, input$y)
```

The extra arguments to `withCache()` are the cache keys --- these are the values used to determine if a computation has occurred before and hence can be retrieved from the cache.

`withCache()` is usually paired with `withEvent()` because if a computation takes long enough that it's worth caching it, it's likely that you'll want to user to manually trigger with an action button or similar.

```{r, eval = FALSE}
r <- reactive() %>% 
  withCache(input$x, input$y) %>% 
  withEvent(input$go)
```

Like `renderCachedPlot()`, `withCache()` has a scope setting.
It defaults to `app` so that you get an in memory cache shared across all users of the app.
But you can `scope = "session"` so that each user session gets its own cache, or to `cachem::disk_cache()` to share across users, processes, and app restarts.
The more aggressively you cache, you more care you'll need to take to manually clear the cache when you change behaviour (e.g. the computation in a reactive) that's not captured by the cache key.

## Manage user expectations

As well as making your app faster, you can also make it seem faster.

<https://www.nngroup.com/articles/progress-indicators/>

Require confirmation before known slow interaction.
Show a Progress bar.
Techniques of Chapter \@ref(action-feedback)

```{r, eval = FALSE}
r <- reactive({
  id <- showNotification("Reading data...", duration = NULL, closeButton = FALSE)
  on.exit(removeNotification(id), add = TRUE)
  
  read.csv(input$path)
}) %>% 
  withCache(input$x, input$y) %>% 
  withEvent(input$go)
```
